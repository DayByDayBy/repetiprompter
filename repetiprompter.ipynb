{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee5adc-0c3e-4b1a-9cba-e2871a183e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs/requirements\n",
    "!pip install ollama tqdm pandas matplotlib seaborn networkx wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the maths on the length/depth\n",
    "\n",
    "chain_length = 5\n",
    "recursion_depth = 5\n",
    "\n",
    "total_chains = sum(chain_length ** i for i in range(recursion_depth))\n",
    "\n",
    "total_chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5dc014-1b88-4a08-a06f-ff2117dcdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "\n",
    "import ollama\n",
    "from typing import Dict, List, Any, Optional\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='tree_generation.log', level=logging.ERROR,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eacfb0-4fad-4428-a440-9352d15e203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config/initialisation\n",
    "\n",
    "TIME_STAMP = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "MODEL_NAME = 'llama3'\n",
    "TEMP=0.67\n",
    "CHAIN_LENGTH = 2\n",
    "RECURSION_DEPTH = 3\n",
    "SHAPE = f'{CHAIN_LENGTH} by {RECURSION_DEPTH}'\n",
    "PROMPT_NICKNAME = 'recursion_prompt'\n",
    "INITIAL_PROMPT = \"consider: the ability to recursively improve upon the present is the key to unlocking the boundless potential of the future, a tool of the gods, the engine of progress, the ultimate weapon in the battle against entropy.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doing the maths on the length/depth \n",
    "\n",
    "# variables redeclared, so you can more easily update them manually to check numbers that arent being used\n",
    "\n",
    "chain_length = CHAIN_LENGTH\n",
    "recursion_depth = RECURSION_DEPTH\n",
    "\n",
    "total_chains = sum(chain_length ** i for i in range(recursion_depth))\n",
    "total_prompt_response_actions = total_chains * chain_length\n",
    "\n",
    "total_chains, total_prompt_response_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25fbab-533d-4ee3-9f0c-4d1993106447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def generate_response(prompt: str) -> str:\n",
    "    try:\n",
    "        return ollama.generate(model=MODEL_NAME, prompt=prompt, options={\"temperature\": TEMP})['response']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def generate_chain(seed_prompt: str, chain_length: int) -> List[str]:\n",
    "    chain = [seed_prompt]\n",
    "    for _ in tqdm(range(chain_length), desc=\"generating chain\", leave=False):\n",
    "        response = generate_response(chain[-1])\n",
    "        if response:\n",
    "            chain.append(response)\n",
    "        else:\n",
    "            break\n",
    "    return chain\n",
    "\n",
    "def generate_tree(seed_prompt: str, chain_length: int, recursion_depth: int, current_depth: int = 1) -> Dict[str, Any]:\n",
    "    chain = generate_chain(seed_prompt, chain_length)\n",
    "    tree = {\"prompt\": seed_prompt, \"responses\": chain[1:]}\n",
    "    \n",
    "    if current_depth < recursion_depth:\n",
    "        tree[\"children\"] = []\n",
    "        for response in tqdm(chain[1:], desc=f\"recursion depth {current_depth}/{recursion_depth}\", leave=False):\n",
    "            child_tree = generate_tree(response, chain_length, recursion_depth, current_depth + 1)\n",
    "            tree[\"children\"].append(child_tree)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def save_tree(tree: Dict[str, Any], metadata: Dict[str, Any], filename: Optional[str] = None):\n",
    "    full_tree = {\n",
    "        \"metadata\": metadata,\n",
    "        \"content\": tree\n",
    "    }\n",
    "    \n",
    "    if filename is None:\n",
    "        filename = f'./responses/ipynb_{metadata[\"model_name\"]}_at_{metadata[\"timestamp\"]}.json'\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(full_tree, f, indent=2)\n",
    "    print(f\"Tree saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa89cc0-0275-497b-80df-c6342f96db35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'\\nRunning {MODEL_NAME} model\\n')\n",
    "\n",
    "metadata = {\n",
    "    \"tree_key\": f'{PROMPT_NICKNAME}_{MODEL_NAME}',\n",
    "    \"timestamp\": TIME_STAMP,\n",
    "    \"shape\": SHAPE,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"chain_length\": CHAIN_LENGTH,\n",
    "    \"recursion_depth\": RECURSION_DEPTH\n",
    "}\n",
    "\n",
    "tree = generate_tree(INITIAL_PROMPT, CHAIN_LENGTH, RECURSION_DEPTH)\n",
    "save_tree(tree, metadata)\n",
    "\n",
    "print(\"\\nGenerated tree saved.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626291f-78be-427a-9e83-5f83313cff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Tree structure:\")\n",
    "# print(json.dumps(tree, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76186e-a32a-4a47-9fc5-1bf530772df1",
   "metadata": {},
   "source": [
    "# visualisation\n",
    "\n",
    "the below is just some visualisation stuff, which can be ignored if you just want to generate the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e3197-5825-43f1-ac91-90f43557f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bf12c-93a7-471b-a2b5-d3d44852f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(colormaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3031e-c1d1-47f6-a809-cda6819edbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "\n",
    "def visualize_tree(tree, max_depth=RECURSION_DEPTH):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    def add_nodes(subtree, parent=None, depth=0):\n",
    "        if depth > max_depth:\n",
    "            return\n",
    "        node_id = len(G.nodes)\n",
    "        G.add_node(node_id, text=subtree['prompt'][:50] + '...', depth=depth)\n",
    "        if parent is not None:\n",
    "            G.add_edge(parent, node_id)\n",
    "        if 'children' in subtree:\n",
    "            for child in subtree['children']:\n",
    "                add_nodes(child, node_id, depth+1)\n",
    "    \n",
    "    add_nodes(tree)\n",
    "\n",
    "    colouring = [G.nodes[node]['depth'] / max_depth for node in G.nodes()]\n",
    "    cmap = cm.get_cmap('bone')\n",
    "    coloring = [(G.nodes[node]['depth'] / max_depth) + (0.15 * (node / len(G.nodes()))) for node in G.nodes()]\n",
    "    coloring = [min(max(val, 0), 1) for val in coloring]  # Ensure values are between 0 and 1\n",
    "    colors = [cmap(color_value) for color_value in coloring]\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(35, 30))\n",
    "    pos = nx.spring_layout(G, iterations=4000)\n",
    "    nx.draw(G, pos, with_labels=True, node_color=colors, \n",
    "            node_size=4000, font_size=10, font_weight='bold')\n",
    "    nx.draw_networkx_labels(G, pos, {node: G.nodes[node]['text'] for node in G.nodes()})\n",
    "    plt.title(\"Tree Structure Visualization\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765f82b-01ad-417a-a9b6-eaa1ef83b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "\n",
    "def get_summary_stats(tree):\n",
    "    all_responses = []\n",
    "    \n",
    "    def collect_responses(subtree):\n",
    "        all_responses.extend(subtree['responses'])\n",
    "        if 'children' in subtree:\n",
    "            for child in subtree['children']:\n",
    "                collect_responses(child)\n",
    "    \n",
    "    collect_responses(tree)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Statistic': ['Total Responses', 'Average Response Length', 'Shortest Response', 'Longest Response'],\n",
    "        'Value': [\n",
    "            len(all_responses),\n",
    "            sum(len(r) for r in all_responses) / len(all_responses),\n",
    "            min(len(r) for r in all_responses),\n",
    "            max(len(r) for r in all_responses)\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"Summary Statistics:\")\n",
    "    display(df)\n",
    "\n",
    "get_summary_stats(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ff8f5-b844-46f9-b2b9-ee1d81fc8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud\n",
    "\n",
    "def generate_word_cloud(tree):\n",
    "    all_text = \"\"\n",
    "    \n",
    "    def collect_text(subtree):\n",
    "        nonlocal all_text\n",
    "        all_text += \" \" + subtree['prompt'] + \" \" + \" \".join(subtree['responses'])\n",
    "        if 'children' in subtree:\n",
    "            for child in subtree['children']:\n",
    "                collect_text(child)\n",
    "    \n",
    "    collect_text(tree)\n",
    "    \n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud of All Responses')\n",
    "    plt.show()\n",
    "\n",
    "generate_word_cloud(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d308260-da46-4e10-b27e-aa9dda8ce401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response length distribution\n",
    "\n",
    "def plot_response_lengths(tree):\n",
    "    lengths = []\n",
    "    \n",
    "    def collect_lengths(subtree):\n",
    "        lengths.extend([len(r) for r in subtree['responses']])\n",
    "        if 'children' in subtree:\n",
    "            for child in subtree['children']:\n",
    "                collect_lengths(child)\n",
    "    \n",
    "    collect_lengths(tree)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(lengths, kde=True)\n",
    "    plt.title('Distribution of Response Lengths')\n",
    "    plt.xlabel('Response Length (characters)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "plot_response_lengths(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa096b98-8c7f-4dbb-90b0-ab09c250ceea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3 repeti (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
