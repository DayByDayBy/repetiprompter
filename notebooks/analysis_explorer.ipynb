{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Response Analysis Explorer\n",
    "\n",
    "This notebook is part pf the `repetiprompter` project.  It provides an interactive exploration of LLM response quality and convergence patterns. It's designed for researchers, engineers, and data scientists who want to understand how language models behave across multiple iterations of recursive improvement. What began as a curiosity led-exploration into recursive prompting has widened into a deeper analysis.\n",
    "\n",
    "## What We'll Analyze Here\n",
    "\n",
    "1. **Structural Stats**: Response length, vocabulary diversity, repetition patterns\n",
    "2. **Quality Signals**: Coherence, information density, specificity, alignment, and hedging\n",
    "3. **Convergence Analysis**: How responses drift or stabilize over time\n",
    "4. **Interactive Exploration**: Filter and drill down into interesting patterns\n",
    "\n",
    "Each metric helps identify strengths, weaknesses, or patterns in the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First, let's ensure we have all necessary dependencies installed. (the project itself uses UV for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_if_missing(package, import_name=None):\n",
    "    if import_name is None:\n",
    "        import_name = package\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Core dependencies\n",
    "install_if_missing(\"pandas\")\n",
    "install_if_missing(\"matplotlib\")\n",
    "install_if_missing(\"seaborn\")\n",
    "install_if_missing(\"numpy\")\n",
    "install_if_missing(\"ipywidgets\")\n",
    "\n",
    "# Optional dependencies for enhanced analysis\n",
    "try:\n",
    "    import spacy\n",
    "    HAS_SPACY = True\n",
    "except ImportError:\n",
    "    HAS_SPACY = False\n",
    "    print(\"\\nspaCy not found. For enhanced entity recognition, install with:\")\n",
    "    print(\"pip install spacy && python -m spacy download en_core_web_sm\")\n",
    "\n",
    "try:\n",
    "    import sentence_transformers\n",
    "    HAS_EMBEDDINGS = True\n",
    "except ImportError:\n",
    "    HAS_EMBEDDINGS = False\n",
    "    print(\"\\nSentence transformers not found. For semantic analysis, install with:\")\n",
    "    print(\"pip install sentence-transformers\")\n",
    "\n",
    "print(\"\\nDependencies checked!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Data Loading\n",
    "\n",
    "Let's import our analysis modules and load a sample run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path / system setup\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the repo root to Python path for imports\n",
    "repo_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Analysis modules\n",
    "from json_analyzers import convergence_tracker as ct\n",
    "from json_analyzers import quality_signals as qs\n",
    "from json_analyzers import structural_stats as ss\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect and load the most recent JSONL file\n",
    "runs_dir = repo_root / \"runs\"\n",
    "\n",
    "jsonl_file = None\n",
    "df_nodes = None\n",
    "\n",
    "if runs_dir.exists():\n",
    "    jsonl_files = list(runs_dir.glob(\"*.jsonl\"))\n",
    "    if jsonl_files:\n",
    "        # Sort by modification time, get the most recent\n",
    "        jsonl_file = max(jsonl_files, key=lambda f: f.stat().st_mtime)\n",
    "        print(f\"Loading: {jsonl_file.name}\")\n",
    "        \n",
    "        # Load nodes into a DataFrame for inspection\n",
    "        with open(jsonl_file, 'r') as f:\n",
    "            nodes = [json.loads(line) for line in f if line.strip()]\n",
    "        \n",
    "        df_nodes = pd.DataFrame(nodes)\n",
    "        print(f\"\\nLoaded {len(df_nodes)} responses\")\n",
    "        print(f\"Run ID: {df_nodes['run_id'].iloc[0]}\")\n",
    "        print(f\"Model: {df_nodes['model_name'].iloc[0]}\")\n",
    "        print(f\"Temperature: {df_nodes['temperature'].iloc[0]}\")\n",
    "        \n",
    "        # Show first few rows\n",
    "        df_nodes.head()\n",
    "    else:\n",
    "        print(\"No JSONL files found in runs/ directory\")\n",
    "else:\n",
    "    print(\"Runs directory not found. Please ensure you're in the correct location.\")\n",
    "\n",
    "# Guard clause - stop if no data loaded\n",
    "if jsonl_file is None:\n",
    "    raise ImportError(\"\\n\\nâš ï¸ NO DATA LOADED: Please ensure you have JSONL files in the runs/ directory before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structural Statistics\n",
    "\n",
    "Structural stats give us the basic shape of our responses - how long they are, how diverse the vocabulary is, and whether they're getting repetitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run structural stats analysis\n",
    "if jsonl_file is None:\n",
    "    print(\"âš ï¸ Cannot run analysis - no data loaded\")\n",
    "else:\n",
    "    struct_results = ss.analyze_structural_stats(jsonl_file)\n",
    "    df_struct = pd.DataFrame(struct_results)\n",
    "\n",
    "# Display summary with highlighting\n",
    "if 'df_struct' not in locals():\n",
    "    print(\"âš ï¸ No structural data available - please run the previous cell first\")\n",
    "else:\n",
    "    def highlight_extremes(df):\n",
    "        styled = df.copy()\n",
    "        # Highlight max values in red, min in blue\n",
    "        for col in ['response_words', 'vocab_diversity', 'repetition_score']:\n",
    "            if col in df.columns:\n",
    "                styled[col] = df[col].apply(\n",
    "                    lambda x: f'**{x:.3f}**' if x == df[col].max() else \n",
    "                    f'*{x:.3f}*' if x == df[col].min() else f'{x:.3f}'\n",
    "                )\n",
    "        return styled\n",
    "\n",
    "    display(Markdown(\"### Structural Statistics Summary\"))\n",
    "    display(df_struct.style.format({\n",
    "        'response_words': '{:.0f}',\n",
    "        'vocab_diversity': '{:.3f}',\n",
    "        'repetition_score': '{:.3f}',\n",
    "        'avg_sentence_length': '{:.1f}'\n",
    "    }).background_gradient(subset=['response_words'], cmap='Blues'))\n",
    "\n",
    "    print(f\"\\nKey Insights:\")\n",
    "    print(f\"- Average response length: {df_struct['response_words'].mean():.0f} words\")\n",
    "    print(f\"- Vocabulary diversity ranges from {df_struct['vocab_diversity'].min():.3f} to {df_struct['vocab_diversity'].max():.3f}\")\n",
    "    print(f\"- Highest repetition score: {df_struct['repetition_score'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot response length over steps with trend line\n",
    "if 'df_struct' not in locals():\n",
    "    print(\"âš ï¸ No structural data available - please run the analysis cells first\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Structural Metrics Over Time', fontsize=16, y=1.02)\n",
    "\n",
    "    # Response length\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(df_struct['step'], df_struct['response_words'], 'o-', alpha=0.7)\n",
    "    z = np.polyfit(df_struct['step'], df_struct['response_words'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax1.plot(df_struct['step'], p(df_struct['step']), \"r--\", alpha=0.5)\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Response Words')\n",
    "    ax1.set_title('Response Length Trend')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Vocabulary diversity\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(df_struct['step'], df_struct['vocab_diversity'], 'o-', color='green', alpha=0.7)\n",
    "    ax2.set_xlabel('Step')\n",
    "    ax2.set_ylabel('Vocabulary Diversity')\n",
    "    ax2.set_title('Vocabulary Diversity')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Repetition score\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(df_struct['step'], df_struct['repetition_score'], 'o-', color='red', alpha=0.7)\n",
    "    ax3.set_xlabel('Step')\n",
    "    ax3.set_ylabel('Repetition Score')\n",
    "    ax3.set_title('Repetition Score (lower is better)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # Depth vs response length\n",
    "    ax4 = axes[1, 1]\n",
    "    scatter = ax4.scatter(df_struct['depth'], df_struct['response_words'], \n",
    "                         c=df_struct['step'], cmap='viridis', s=100, alpha=0.7)\n",
    "    ax4.set_xlabel('Depth')\n",
    "    ax4.set_ylabel('Response Words')\n",
    "    ax4.set_title('Response Length by Depth')\n",
    "    plt.colorbar(scatter, ax=ax4, label='Step')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quality Signals Analysis\n",
    "\n",
    "This section analyzes the linguistic and semantic quality of LLM responses. Each metric helps identify strengths, weaknesses, or patterns in the generated text.\n",
    "\n",
    "### Key Metrics Explained\n",
    "\n",
    "| Metric | Description | Why It Matters |\n",
    "|--------|-------------|----------------|\n",
    "| **Coherence Variance** | Measures how consistent the logical flow of a response is across steps. | High variance may indicate unstable or contradictory reasoning. |\n",
    "| **Information Density** | Ratio of unique, meaningful content to total words. | High density suggests concise, informative responses. |\n",
    "| **Specificity** | Degree to which responses include concrete details (e.g., numbers, names, examples). | Low specificity can signal generic or unhelpful outputs. |\n",
    "| **Alignment** | How well responses match the user's intent or query. | Misalignment may reveal misunderstandings or biases in the LLM. |\n",
    "| **Hedge Density** | Frequency of uncertain language (e.g., \"might,\" \"possibly\"). | High density can indicate low confidence or overly cautious responses. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run quality signals analysis\n",
    "print(\"Analyzing quality signals...\")\n",
    "quality_results = qs.analyze_quality_signals(\n",
    "    jsonl_file, \n",
    "    use_embeddings=HAS_EMBEDDINGS, \n",
    "    use_spacy=HAS_SPACY\n",
    ")\n",
    "df_quality = pd.DataFrame(quality_results)\n",
    "\n",
    "# Display quality metrics summary\n",
    "display(Markdown(\"### Quality Metrics Summary\"))\n",
    "quality_cols = ['coherence_variance', 'info_density', 'specificity', 'alignment', 'hedge_density']\n",
    "available_cols = [col for col in quality_cols if col in df_quality.columns]\n",
    "\n",
    "if available_cols:\n",
    "    display(df_quality[['step', 'node_id'] + available_cols].style.background_gradient(\n",
    "        subset=available_cols, cmap='RdYlBu_r'\n",
    "    ).format({col: '{:.3f}' for col in available_cols}))\n",
    "else:\n",
    "    print(\"No quality metrics available. Check if analysis ran correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive quality visualization\n",
    "if 'coherence_variance' in df_quality.columns and 'info_density' in df_quality.columns:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create scatter plot\n",
    "    scatter = sns.scatterplot(\n",
    "        x='coherence_variance',\n",
    "        y='info_density',\n",
    "        hue='step',\n",
    "        data=df_quality,\n",
    "        palette='viridis',\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Coherence vs. Information Density by Step\", fontsize=14, pad=20)\n",
    "    plt.xlabel(\"Coherence Variance (lower = better)\", fontsize=12)\n",
    "    plt.ylabel(\"Information Density (higher = better)\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Add quadrants labels\n",
    "    plt.text(0.02, 0.98, 'Ideal', transform=plt.gca().transAxes, \n",
    "             fontsize=12, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "    plt.text(0.98, 0.02, 'Problematic', transform=plt.gca().transAxes, \n",
    "             fontsize=12, horizontalalignment='right',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.3))\n",
    "    \n",
    "    # Annotate outliers\n",
    "    for i, row in df_quality.iterrows():\n",
    "        if row['coherence_variance'] > 0.8 or row['info_density'] < 0.2:\n",
    "            plt.annotate(\n",
    "                f\"Step {row['step']}\",\n",
    "                (row['coherence_variance'], row['info_density']),\n",
    "                fontsize=9,\n",
    "                alpha=0.8,\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points'\n",
    "            )\n",
    "    \n",
    "    # Add colorbar\n",
    "    norm = plt.Normalize(df_quality['step'].min(), df_quality['step'].max())\n",
    "    sm = plt.cm.ScalarMappable(cmap='viridis', norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, label='Step')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print insights\n",
    "    print(\"\\n### Quality Insights:\")\n",
    "    print(f\"- Average coherence variance: {df_quality['coherence_variance'].mean():.3f}\")\n",
    "    print(f\"- Average information density: {df_quality['info_density'].mean():.3f}\")\n",
    "    \n",
    "    # Find best and worst responses\n",
    "    best_idx = df_quality['info_density'].idxmax()\n",
    "    worst_idx = df_quality['coherence_variance'].idxmax()\n",
    "    \n",
    "    print(f\"\\nMost informative response: Step {df_quality.loc[best_idx, 'step']} \"\n",
    "          f\"(density: {df_quality.loc[best_idx, 'info_density']:.3f})\")\n",
    "    print(f\"Least coherent response: Step {df_quality.loc[worst_idx, 'step']} \"\n",
    "          f\"(variance: {df_quality.loc[worst_idx, 'coherence_variance']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actionable Insights\n",
    "\n",
    "#### High Coherence Variance:\n",
    "- Check if the LLM's context window or prompts need adjustment\n",
    "- Example: Add constraints like \"Respond in 3 bullet points\" to reduce variability\n",
    "\n",
    "#### Low Information Density:\n",
    "- Use post-processing to filter repetitive phrases\n",
    "- Prompt the LLM to \"elaborate with examples\"\n",
    "\n",
    "#### High Hedge Density:\n",
    "- Experiment with temperature settings\n",
    "- Add \"Be confident in your answer\" to prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convergence Analysis\n",
    "\n",
    "Convergence analysis helps us understand if the LLM is stabilizing on a solution or drifting aimlessly. We look for plateaus (stable periods) and fixed points (exact repetitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run convergence tracker\n",
    "print(\"Running convergence analysis...\")\n",
    "summary = ct.analyze_convergence(jsonl_file, use_embeddings=HAS_EMBEDDINGS)\n",
    "df_converge = pd.DataFrame(summary['per_node_results'])\n",
    "\n",
    "# Display convergence summary\n",
    "display(Markdown(\"### Convergence Summary\"))\n",
    "print(f\"Total steps analyzed: {len(df_converge)}\")\n",
    "print(f\"Average drift from root: {df_converge['drift_from_root'].mean():.3f}\")\n",
    "print(f\"Number of plateaus detected: {len(summary['plateaus'])}\")\n",
    "\n",
    "if summary['fixed_point_step']:\n",
    "    print(f\"Fixed point reached at step: {summary['fixed_point_step']}\")\n",
    "else:\n",
    "    print(\"No fixed point detected (responses kept changing)\")\n",
    "\n",
    "# Show plateau details\n",
    "if summary['plateaus']:\n",
    "    print(\"\\nPlateau periods:\")\n",
    "    for i, (start, end) in enumerate(summary['plateaus'][:5], 1):\n",
    "        print(f\"  {i}. Steps {start}-{end} (duration: {end-start+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence with plateaus and fixed points\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Main convergence plot\n",
    "ax1.plot(df_converge['step'], df_converge['drift_from_root'], \n",
    "         'o-', linewidth=2, markersize=6, alpha=0.8)\n",
    "\n",
    "# Highlight plateaus\n",
    "for i, (start, end) in enumerate(summary['plateaus']):\n",
    "    ax1.axvspan(start, end, color='orange', alpha=0.2, label='Plateau' if i == 0 else '')\n",
    "    # Add plateau label\n",
    "    mid_point = (start + end) / 2\n",
    "    max_drift = df_converge.loc[(df_converge['step'] >= start) & (df_converge['step'] <= end), 'drift_from_root'].max()\n",
    "    ax1.text(mid_point, max_drift + 0.02, f'Plateau\\n({end-start+1} steps)', \n",
    "             ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Fixed point line\n",
    "if summary['fixed_point_step']:\n",
    "    ax1.axvline(summary['fixed_point_step'], color='red', linestyle='--', \n",
    "                linewidth=2, label='Fixed Point')\n",
    "    ax1.text(summary['fixed_point_step'], ax1.get_ylim()[1]*0.9, \n",
    "             'Fixed\\nPoint', ha='center', va='top', fontsize=9,\n",
    "             bbox=dict(boxstyle='round', facecolor='red', alpha=0.2))\n",
    "\n",
    "ax1.set_xlabel('Step', fontsize=12)\n",
    "ax1.set_ylabel('Drift from Root', fontsize=12)\n",
    "ax1.set_title('Convergence Analysis: Drift Over Steps', fontsize=14, pad=20)\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Drift gradient plot\n",
    "if len(df_converge) > 2:\n",
    "    gradients = np.gradient(df_converge['drift_from_root'])\n",
    "    ax2.bar(df_converge['step'], gradients, alpha=0.7, color='purple')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.set_xlabel('Step', fontsize=12)\n",
    "    ax2.set_ylabel('Drift Gradient', fontsize=12)\n",
    "    ax2.set_title('Rate of Change (Gradient)', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight significant changes\n",
    "    threshold = np.std(gradients)\n",
    "    significant = np.abs(gradients) > threshold\n",
    "    if np.any(significant):\n",
    "        ax2.scatter(df_converge.loc[significant, 'step'], \n",
    "                   gradients[significant], \n",
    "                   color='red', s=50, zorder=5, label='Significant Change')\n",
    "        ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Exploration\n",
    "\n",
    "Use the widgets below to explore the data. Filter by different metrics to find interesting patterns or problematic responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive filtering dashboard\n",
    "style = {'description_width': '120px'}\n",
    "layout = widgets.Layout(width='400px')\n",
    "\n",
    "# Create widgets for filtering\n",
    "step_slider = widgets.IntRangeSlider(\n",
    "    value=[0, len(df_nodes)-1],\n",
    "    min=0,\n",
    "    max=len(df_nodes)-1,\n",
    "    step=1,\n",
    "    description='Step Range:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "rep_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Max Repetition:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "hedge_slider = widgets.FloatSlider(\n",
    "    value=0.3,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Max Hedge Density:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "density_slider = widgets.FloatSlider(\n",
    "    value=0.2,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Min Info Density:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "metric_dropdown = widgets.Dropdown(\n",
    "    options=['Response Length', 'Vocabulary Diversity', 'Repetition Score', \n",
    "             'Coherence', 'Info Density', 'Hedge Density'],\n",
    "    value='Response Length',\n",
    "    description='Plot Metric:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_dashboard(*args):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Apply filters\n",
    "        mask = (\n",
    "            (df_struct['step'] >= step_slider.value[0]) &\n",
    "            (df_struct['step'] <= step_slider.value[1]) &\n",
    "            (df_struct['repetition_score'] <= rep_slider.value)\n",
    "        )\n",
    "        \n",
    "        # Add quality filters if available\n",
    "        if 'hedge_density' in df_quality.columns:\n",
    "            mask = mask & (df_quality['hedge_density'] <= hedge_slider.value)\n",
    "        if 'info_density' in df_quality.columns:\n",
    "            mask = mask & (df_quality['info_density'] >= density_slider.value)\n",
    "        \n",
    "        filtered_struct = df_struct[mask]\n",
    "        filtered_quality = df_quality[mask] if not df_quality.empty else pd.DataFrame()\n",
    "        \n",
    "        # Display summary\n",
    "        display(Markdown(f\"### Filtered Results: {len(filtered_struct)} responses\"))\n",
    "        \n",
    "        if not filtered_struct.empty:\n",
    "            # Create plot based on selected metric\n",
    "            fig, ax = plt.subplots(figsize=(10, 4))\n",
    "            \n",
    "            metric_map = {\n",
    "                'Response Length': 'response_words',\n",
    "                'Vocabulary Diversity': 'vocab_diversity',\n",
    "                'Repetition Score': 'repetition_score',\n",
    "                'Coherence': 'coherence_variance',\n",
    "                'Info Density': 'info_density',\n",
    "                'Hedge Density': 'hedge_density'\n",
    "            }\n",
    "            \n",
    "            selected_metric = metric_map[metric_dropdown.value]\n",
    "            \n",
    "            if selected_metric in filtered_struct.columns:\n",
    "                ax.plot(filtered_struct['step'], filtered_struct[selected_metric], \n",
    "                       'o-', linewidth=2, markersize=6)\n",
    "            elif selected_metric in filtered_quality.columns:\n",
    "                ax.plot(filtered_quality['step'], filtered_quality[selected_metric], \n",
    "                       'o-', linewidth=2, markersize=6, color='orange')\n",
    "            \n",
    "            ax.set_xlabel('Step')\n",
    "            ax.set_ylabel(metric_dropdown.value)\n",
    "            ax.set_title(f'{metric_dropdown.value} Over Filtered Steps')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.show()\n",
    "            \n",
    "            # Show table of extreme values\n",
    "            display(Markdown(\"#### Extreme Values:\"))\n",
    "            if selected_metric in filtered_struct.columns:\n",
    "                extreme = filtered_struct.nlargest(3, selected_metric) if 'Score' not in metric_dropdown.value else filtered_struct.nsmallest(3, selected_metric)\n",
    "            else:\n",
    "                extreme = filtered_quality.nlargest(3, selected_metric) if 'Score' not in metric_dropdown.value else filtered_quality.nsmallest(3, selected_metric)\n",
    "            \n",
    "            display(extreme[['step', 'node_id', selected_metric]].style.background_gradient(\n",
    "                subset=[selected_metric], cmap='RdYlBu_r'\n",
    "            ))\n",
    "\n",
    "# Connect widgets to update function\n",
    "for widget in [step_slider, rep_slider, hedge_slider, density_slider, metric_dropdown]:\n",
    "    widget.observe(update_dashboard, 'value')\n",
    "\n",
    "# Display the dashboard\n",
    "display(Markdown(\"### Interactive Filtering Dashboard\"))\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([step_slider, rep_slider]),\n",
    "    widgets.HBox([hedge_slider, density_slider]),\n",
    "    metric_dropdown,\n",
    "    output\n",
    "]))\n",
    "\n",
    "# Initial update\n",
    "update_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Filtered Data\n",
    "\n",
    "Use this cell to export your filtered results for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export functionality\n",
    "export_button = widgets.Button(description=\"Export to CSV\", button_style='success')\n",
    "filename_input = widgets.Text(value='filtered_results.csv', description='Filename:')\n",
    "\n",
    "def export_data(b):\n",
    "    # Apply current filters\n",
    "    mask = (\n",
    "        (df_struct['step'] >= step_slider.value[0]) &\n",
    "        (df_struct['step'] <= step_slider.value[1]) &\n",
    "        (df_struct['repetition_score'] <= rep_slider.value)\n",
    "    )\n",
    "    \n",
    "    if 'hedge_density' in df_quality.columns:\n",
    "        mask = mask & (df_quality['hedge_density'] <= hedge_slider.value)\n",
    "    if 'info_density' in df_quality.columns:\n",
    "        mask = mask & (df_quality['info_density'] >= density_slider.value)\n",
    "    \n",
    "    # Merge structural and quality data\n",
    "    filtered_struct = df_struct[mask].copy()\n",
    "    filtered_quality = df_quality[mask].copy() if not df_quality.empty else pd.DataFrame()\n",
    "    \n",
    "    if not filtered_quality.empty:\n",
    "        merged = filtered_struct.merge(filtered_quality[['step', 'node_id'] + available_cols], \n",
    "                                      on=['step', 'node_id'], how='left')\n",
    "    else:\n",
    "        merged = filtered_struct\n",
    "    \n",
    "    # Export\n",
    "    output_path = Path.cwd() / filename_input.value\n",
    "    merged.to_csv(output_path, index=False)\n",
    "    print(f\"Exported {len(merged)} rows to {output_path}\")\n",
    "\n",
    "export_button.on_click(export_data)\n",
    "display(widgets.HBox([filename_input, export_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary & Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "Based on the analysis above, here are the key findings from this run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate automatic summary\n",
    "display(Markdown(\"### Run Summary\"))\n",
    "\n",
    "# Basic stats\n",
    "total_responses = len(df_nodes)\n",
    "avg_length = df_struct['response_words'].mean()\n",
    "length_std = df_struct['response_words'].std()\n",
    "avg_diversity = df_struct['vocab_diversity'].mean()\n",
    "avg_repetition = df_struct['repetition_score'].mean()\n",
    "\n",
    "print(f\"ðŸ“Š **Basic Statistics:**\")\n",
    "print(f\"   - Total responses: {total_responses}\")\n",
    "print(f\"   - Average length: {avg_length:.0f} Â± {length_std:.0f} words\")\n",
    "print(f\"   - Vocabulary diversity: {avg_diversity:.3f} on average\")\n",
    "print(f\"   - Repetition score: {avg_repetition:.3f} on average\")\n",
    "\n",
    "# Quality insights\n",
    "if not df_quality.empty:\n",
    "    print(f\"\\nðŸŽ¯ **Quality Insights:**\")\n",
    "    if 'coherence_variance' in df_quality.columns:\n",
    "        coherence_trend = 'improving' if df_quality['coherence_variance'].iloc[-1] < df_quality['coherence_variance'].iloc[0] else 'degrading'\n",
    "        print(f\"   - Coherence is {coherence_trend} over time\")\n",
    "    if 'info_density' in df_quality.columns:\n",
    "        density_trend = 'improving' if df_quality['info_density'].iloc[-1] > df_quality['info_density'].iloc[0] else 'degrading'\n",
    "        print(f\"   - Information density is {density_trend} over time\")\n",
    "    if 'hedge_density' in df_quality.columns:\n",
    "        avg_hedge = df_quality['hedge_density'].mean()\n",
    "        confidence = 'confident' if avg_hedge < 0.2 else 'cautious' if avg_hedge < 0.4 else 'very uncertain'\n",
    "        print(f\"   - LLM appears {confidence} (hedge density: {avg_hedge:.3f})\")\n",
    "\n",
    "# Convergence insights\n",
    "print(f\"\\nðŸ”„ **Convergence Patterns:**\")\n",
    "if summary['fixed_point_step']:\n",
    "    print(f\"   - âœ… Reached fixed point at step {summary['fixed_point_step']}\")\n",
    "else:\n",
    "    print(f\"   - âŒ No fixed point reached (responses kept evolving)\")\n",
    "\n",
    "if summary['plateaus']:\n",
    "    longest_plateau = max(summary['plateaus'], key=lambda p: p[1] - p[0])\n",
    "    plateau_duration = longest_plateau[1] - longest_plateau[0] + 1\n",
    "    print(f\"   - Found {len(summary['plateaus'])} plateaus, longest lasting {plateau_duration} steps\")\n",
    "else:\n",
    "    print(f\"   - No stable plateaus detected\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nðŸ’¡ **Recommendations:**\")\n",
    "\n",
    "if avg_repetition > 0.3:\n",
    "    print(f\"   - High repetition detected. Consider lowering temperature or adding variety prompts.\")\n",
    "\n",
    "if length_std > avg_length * 0.5:\n",
    "    print(f\"   - High variability in response length. Consider adding length constraints.\")\n",
    "\n",
    "if not summary['fixed_point_step'] and len(df_nodes) > 10:\n",
    "    print(f\"   - Responses didn't converge. This might indicate good exploration or lack of focus.\")\n",
    "\n",
    "if avg_diversity < 0.5:\n",
    "    print(f\"   - Low vocabulary diversity. Try prompting for more varied expression.\")\n",
    "\n",
    "print(f\"\\nðŸ” **Next Steps to Explore:**\")\n",
    "print(f\"   1. Try with embeddings enabled for semantic analysis\")\n",
    "print(f\"   2. Compare multiple runs to spot consistent patterns\")\n",
    "print(f\"   3. Analyze specific branches that showed interesting behavior\")\n",
    "print(f\"   4. Export data for custom visualizations or statistical tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try It Yourself!\n",
    "\n",
    "Here are some ideas for further exploration:\n",
    "\n",
    "1. **Compare Different Models**: Run the same prompt with different models and compare their convergence patterns\n",
    "2. **Temperature Effects**: Analyze how temperature settings affect repetition and coherence\n",
    "3. **Prompt Engineering**: Test different prompt strategies and see how they impact quality metrics\n",
    "4. **Multi-Run Analysis**: Load multiple JSONL files and compare aggregate statistics\n",
    "5. **Custom Metrics**: Add your own quality metrics based on domain-specific needs\n",
    "\n",
    "### Share Your Findings!\n",
    "\n",
    "If you discover interesting patterns or have suggestions for improving this analysis, please share them with the community. Your insights help make these tools better for everyone.\n",
    "\n",
    "---\n",
    "\n",
    "*Last updated: January 2026*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
